                                                                    Ejemplo de BigData Processing

La idea de este proyecto consta de 3 capas, la de Batch, la de provisioner y la de Sreaming. Cada una de ellas realizara una funcion como generacion de datos en streaming, almancenamiento en la nube y asi como lectura y escritura de datos.

La de Batch no la he conseguido hacer bien porque los inputs de parquet no los conseguia realizar mediante la de Streaming ##

Configure Kafka, y me enviaba mensajes y todo salia bien. Sin embargo no almacenaba los datos. Comprobe las instancias y maquinas virtuales y parecen estar bien

La capa de Provisioner no da errores y genera bien los archivos

La capa de streaming parece que funciona bien, se conecta y genera los datos pero como te he dicho antes se queda en bucle inf como tengo puesto pero lo he dejado 30 min y no me genera todos los datos ##

Creo que necesito mas tiempo pero podria sacarlo, me ha gustado el tema de los sensores y la idea es comoda y facil, pero creo que tengo que realizar mas codigo

*** El proyecto lo he guardado comprimido en .zip con el nombre de practica *** 

Se supone que alli esta todo lo necesario
